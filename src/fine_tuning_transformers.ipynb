{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install -U git+https://github.com/huggingface/transformers.git\n! pip install -U git+https://github.com/huggingface/accelerate.git\n!pip install datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -- Libraries\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader\nfrom transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\nfrom sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\nfrom datasets import Dataset\nfrom tqdm import tqdm\nimport pandas   as pd\nimport numpy    as np\nimport torch.nn as nn\nimport itertools\nimport torch\nimport glob\nimport ast","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-02T16:56:03.787921Z","iopub.execute_input":"2023-07-02T16:56:03.788317Z","iopub.status.idle":"2023-07-02T16:56:03.796786Z","shell.execute_reply.started":"2023-07-02T16:56:03.788284Z","shell.execute_reply":"2023-07-02T16:56:03.795215Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Read data","metadata":{}},{"cell_type":"code","source":"# -- Load train data\nfiles_list  = glob.glob('/kaggle/input/mentalris-original-data/train_data/task2_train/*')\nsubjects_id = [[file.split('/')[-1].replace('.json', '')] * pd.read_json(file).shape[0] for file in files_list]\nsubjects_id = list(itertools.chain(*subjects_id))\n\ntrain_df    = pd.concat([pd.read_json(file) for file in files_list],\n                         axis=0)\ntrain_df['Subject'] = subjects_id\ntrain_df_labels     = pd.read_table('/kaggle/input/mentalris-original-data/train_data/task2_gold_a.txt', sep=',')\ntrain_df = train_df.merge(train_df_labels, on='Subject')\n\n# -- Load trial data\nfiles_list  = glob.glob('/kaggle/input/mentalris-original-data/trial_data/task2_trial/*')\nsubjects_id = [[file.split('/')[-1].replace('.json', '')] * pd.read_json(file).shape[0] for file in files_list]\nsubjects_id = list(itertools.chain(*subjects_id))\n\ntrial_df            = pd.concat([pd.read_json(file) for file in files_list],\n                                 axis=0)\ntrial_df['Subject'] = subjects_id\ntrial_df_labels     = pd.read_table('/kaggle/input/mentalris-original-data/trial_data/task2_gold_a.txt', sep=',')\ntrial_df            = trial_df.merge(trial_df_labels, on='Subject')\n\ntrain_df = pd.concat([trial_df, train_df], axis=0)\ntrain_df = train_df[['Subject', 'message', 'label']]\n\n# -- Load test data\ntest_df = pd.read_excel('/kaggle/input/test-data-excel-formatted/test_data.xlsx')\ntest_df_labels = pd.read_table('/kaggle/input/test-gold-labels/task2_gold_a.csv', sep=',')\ntest_df        = test_df.merge(test_df_labels, left_on='nick', right_on='Subject')\ntest_df = test_df[['nick', 'message', 'label']]\n\n\ntrain_df.rename(columns={'Subject': 'Subject_ID', 'message': 'Text', 'label': 'type'}, inplace=True)\ntest_df.rename(columns={'nick': 'Subject_ID', 'message': 'Text', 'label': 'type'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T16:49:29.305784Z","iopub.execute_input":"2023-07-02T16:49:29.306139Z","iopub.status.idle":"2023-07-02T16:49:33.301012Z","shell.execute_reply.started":"2023-07-02T16:49:29.306109Z","shell.execute_reply":"2023-07-02T16:49:33.299866Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_df['Class'] = 'train'\ntest_df['Class'] = 'test'\nerisk_df_no_blank_posts = pd.concat([train_df, test_df], axis=0)\nerisk_df_no_blank_posts.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T16:49:33.303273Z","iopub.execute_input":"2023-07-02T16:49:33.303628Z","iopub.status.idle":"2023-07-02T16:49:33.326218Z","shell.execute_reply.started":"2023-07-02T16:49:33.303594Z","shell.execute_reply":"2023-07-02T16:49:33.325246Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  Subject_ID                                               Text  type  Class\n0  subject10             umm pues como te explico ... mal : ´ (     1  train\n1  subject10  pues jajaj seria muy bueno , me pasan demasiad...     1  train\n2  subject10  ojala y solo fuese ese el problema , en mi cas...     1  train\n3  subject10  pues son varias , me gusta bailar de hecho soy...     1  train\n4  subject10  eso es lo que trato ahora , me cansé de presta...     1  train","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Subject_ID</th>\n      <th>Text</th>\n      <th>type</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>subject10</td>\n      <td>umm pues como te explico ... mal : ´ (</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>subject10</td>\n      <td>pues jajaj seria muy bueno , me pasan demasiad...</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>subject10</td>\n      <td>ojala y solo fuese ese el problema , en mi cas...</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>subject10</td>\n      <td>pues son varias , me gusta bailar de hecho soy...</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>subject10</td>\n      <td>eso es lo que trato ahora , me cansé de presta...</td>\n      <td>1</td>\n      <td>train</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"__Group data__","metadata":{}},{"cell_type":"code","source":"erisk_df_no_blank_posts = erisk_df_no_blank_posts.groupby(['Subject_ID', 'type', 'Class'])['Text'].apply(lambda x: ' '.join(x)).reset_index()\nerisk_df_no_blank_posts","metadata":{"execution":{"iopub.status.busy":"2023-07-02T16:49:33.327504Z","iopub.execute_input":"2023-07-02T16:49:33.327942Z","iopub.status.idle":"2023-07-02T16:49:33.375156Z","shell.execute_reply.started":"2023-07-02T16:49:33.327908Z","shell.execute_reply":"2023-07-02T16:49:33.374017Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"     Subject_ID  type  Class  \\\n0      subject1     0  train   \n1     subject10     1  train   \n2    subject100     1  train   \n3    subject101     1  train   \n4    subject102     1  train   \n..          ...   ...    ...   \n329   subject86     0   test   \n330    subject9     0   test   \n331   subject91     0   test   \n332   subject92     0   test   \n333   subject93     0   test   \n\n                                                  Text  \n0    Bien ... técnicamente debería irme a dormir ca...  \n1    umm pues como te explico ... mal : ´ ( pues ja...  \n2    Hola , estoy realmente mal , no se que hacer c...  \n3    volvi me extrañaron signo de interrogación y t...  \n4    ¿ Cuanto tiempo duraron así ? sí , pero ya nos...  \n..                                                 ...  \n329  La soledad y el tiempo son el mejor aleado par...  \n330  Hola necesito consejos tengo una hija con depr...  \n331  El insomnio no me deja Hay un virus dando cuen...  \n332  Alguna chica me consuela ? Mejor llorar en dos...  \n333  Hay cosas que me gustan , pero aveces me desmo...  \n\n[334 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Subject_ID</th>\n      <th>type</th>\n      <th>Class</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>subject1</td>\n      <td>0</td>\n      <td>train</td>\n      <td>Bien ... técnicamente debería irme a dormir ca...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>subject10</td>\n      <td>1</td>\n      <td>train</td>\n      <td>umm pues como te explico ... mal : ´ ( pues ja...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>subject100</td>\n      <td>1</td>\n      <td>train</td>\n      <td>Hola , estoy realmente mal , no se que hacer c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>subject101</td>\n      <td>1</td>\n      <td>train</td>\n      <td>volvi me extrañaron signo de interrogación y t...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>subject102</td>\n      <td>1</td>\n      <td>train</td>\n      <td>¿ Cuanto tiempo duraron así ? sí , pero ya nos...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>329</th>\n      <td>subject86</td>\n      <td>0</td>\n      <td>test</td>\n      <td>La soledad y el tiempo son el mejor aleado par...</td>\n    </tr>\n    <tr>\n      <th>330</th>\n      <td>subject9</td>\n      <td>0</td>\n      <td>test</td>\n      <td>Hola necesito consejos tengo una hija con depr...</td>\n    </tr>\n    <tr>\n      <th>331</th>\n      <td>subject91</td>\n      <td>0</td>\n      <td>test</td>\n      <td>El insomnio no me deja Hay un virus dando cuen...</td>\n    </tr>\n    <tr>\n      <th>332</th>\n      <td>subject92</td>\n      <td>0</td>\n      <td>test</td>\n      <td>Alguna chica me consuela ? Mejor llorar en dos...</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>subject93</td>\n      <td>0</td>\n      <td>test</td>\n      <td>Hay cosas que me gustan , pero aveces me desmo...</td>\n    </tr>\n  </tbody>\n</table>\n<p>334 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Verificar si hay una GPU disponible\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2023-07-02T16:49:33.377994Z","iopub.execute_input":"2023-07-02T16:49:33.379053Z","iopub.status.idle":"2023-07-02T16:49:33.387939Z","shell.execute_reply.started":"2023-07-02T16:49:33.379011Z","shell.execute_reply":"2023-07-02T16:49:33.386543Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"# Definir el modelo y el tokenizer\nmodel_name = \"PlanTL-GOB-ES/roberta-base-bne\"\ntokenizer = RobertaTokenizer.from_pretrained(model_name)\nmodel = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n\n# Definir los datos de entrenamiento y prueba (como DataFrames)\n# Reemplaza train_df y test_df con tus propios DataFrames\nerisk_df_no_blank_posts.rename(columns={'type': 'labels', 'Text': 'text'}, inplace=True)\ntrain_df, test_df = erisk_df_no_blank_posts[erisk_df_no_blank_posts['Class'] == 'train'],\\\n                    erisk_df_no_blank_posts[erisk_df_no_blank_posts['Class'] == 'test']\n\ntest_df  = test_df[['labels', 'text']]\ntrain_df = train_df[['labels', 'text']]\n\n# Función para la tokenización y codificación de los datos\ndef tokenize_data(data):\n    texts = data[\"text\"].tolist()\n    labels = data[\"labels\"].tolist()  # Ajusta el nombre de la columna que contiene las etiquetas\n    encoded_inputs = tokenizer(texts, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n    encoded_inputs[\"labels\"] = torch.tensor(labels)\n    return encoded_inputs\n\ntrain_encoded = tokenize_data(train_df)\nval_encoded = tokenize_data(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T16:49:38.841315Z","iopub.execute_input":"2023-07-02T16:49:38.841681Z","iopub.status.idle":"2023-07-02T16:49:53.939787Z","shell.execute_reply.started":"2023-07-02T16:49:38.841651Z","shell.execute_reply":"2023-07-02T16:49:53.938742Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/851k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f5f33f1a77f451a9326279aefa21bad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/509k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"311577b6eb844f969260ae2be001452e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/957 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"667a5831c44c485babf8c79c32e43ddb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe398de1c9b14d8caf7ac4e341430969"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/613 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20429abf9fab4634b85fe8f95a80eca3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"abd4ce527fb94906a1be88e5d09d43ba"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Convertir los datos codificados en objetos Dataset\ntrain_dataset = Dataset.from_dict(train_encoded)\nval_dataset = Dataset.from_dict(val_encoded)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T16:49:53.941708Z","iopub.execute_input":"2023-07-02T16:49:53.942175Z","iopub.status.idle":"2023-07-02T16:49:54.031020Z","shell.execute_reply.started":"2023-07-02T16:49:53.942139Z","shell.execute_reply":"2023-07-02T16:49:54.030028Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Configuración del entrenamiento\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    metric_for_best_model=\"eval_f1\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=16,\n    learning_rate=2e-5,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    eval_steps=500,\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T16:49:54.032433Z","iopub.execute_input":"2023-07-02T16:49:54.033061Z","iopub.status.idle":"2023-07-02T16:49:55.832183Z","shell.execute_reply.started":"2023-07-02T16:49:54.033026Z","shell.execute_reply":"2023-07-02T16:49:55.831009Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Métricas personalizadas\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(axis=-1)\n    \n    f1 = f1_score(labels, predictions, average=\"binary\")\n    f1_weighted = f1_score(labels, predictions, average=\"weighted\")\n    recall = recall_score(labels, predictions, average=\"binary\")\n    recall_macro = recall_score(labels, predictions, average=\"macro\")\n    precision = precision_score(labels, predictions, average=\"binary\")\n    precision_macro = precision_score(labels, predictions, average=\"macro\")\n    \n    return {\n        \"eval_f1\": f1,\n        \"eval_f1_weighted\": f1_weighted,\n        \"eval_recall\": recall,\n        \"eval_recall_macro\": recall_macro,\n        \"eval_precision\": precision,\n        \"eval_precision_macro\": precision_macro,\n    }","metadata":{"execution":{"iopub.status.busy":"2023-07-02T16:49:58.107338Z","iopub.execute_input":"2023-07-02T16:49:58.108086Z","iopub.status.idle":"2023-07-02T16:49:58.116169Z","shell.execute_reply.started":"2023-07-02T16:49:58.108050Z","shell.execute_reply":"2023-07-02T16:49:58.115046Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Entrenamiento del modelo\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T16:49:59.397918Z","iopub.execute_input":"2023-07-02T16:49:59.398291Z","iopub.status.idle":"2023-07-02T16:49:59.412219Z","shell.execute_reply.started":"2023-07-02T16:49:59.398261Z","shell.execute_reply":"2023-07-02T16:49:59.411337Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-07-02T16:50:00.885001Z","iopub.execute_input":"2023-07-02T16:50:00.885389Z","iopub.status.idle":"2023-07-02T16:52:12.946326Z","shell.execute_reply.started":"2023-07-02T16:50:00.885356Z","shell.execute_reply":"2023-07-02T16:52:12.945260Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230702_165014-aw4fv68a</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/albertofernandez/huggingface/runs/aw4fv68a' target=\"_blank\">desert-hill-27</a></strong> to <a href='https://wandb.ai/albertofernandez/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/albertofernandez/huggingface' target=\"_blank\">https://wandb.ai/albertofernandez/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/albertofernandez/huggingface/runs/aw4fv68a' target=\"_blank\">https://wandb.ai/albertofernandez/huggingface/runs/aw4fv68a</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 01:18, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n      <th>F1 Weighted</th>\n      <th>Recall</th>\n      <th>Recall Macro</th>\n      <th>Precision</th>\n      <th>Precision Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.680800</td>\n      <td>0.686718</td>\n      <td>0.626728</td>\n      <td>0.286024</td>\n      <td>1.000000</td>\n      <td>0.500000</td>\n      <td>0.456376</td>\n      <td>0.228188</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.646900</td>\n      <td>0.599662</td>\n      <td>0.702703</td>\n      <td>0.599725</td>\n      <td>0.955882</td>\n      <td>0.656954</td>\n      <td>0.555556</td>\n      <td>0.730903</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.446200</td>\n      <td>0.400871</td>\n      <td>0.814815</td>\n      <td>0.832108</td>\n      <td>0.808824</td>\n      <td>0.830338</td>\n      <td>0.820896</td>\n      <td>0.831179</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.340800</td>\n      <td>0.481755</td>\n      <td>0.792208</td>\n      <td>0.784363</td>\n      <td>0.897059</td>\n      <td>0.794208</td>\n      <td>0.709302</td>\n      <td>0.799096</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.170000</td>\n      <td>0.444674</td>\n      <td>0.786667</td>\n      <td>0.785099</td>\n      <td>0.867647</td>\n      <td>0.791848</td>\n      <td>0.719512</td>\n      <td>0.792592</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=60, training_loss=0.41928551395734154, metrics={'train_runtime': 131.7242, 'train_samples_per_second': 7.022, 'train_steps_per_second': 0.455, 'total_flos': 243377726208000.0, 'train_loss': 0.41928551395734154, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"# Test phase","metadata":{}},{"cell_type":"code","source":"# -- Load best model obtained from training phase\nmodel = RobertaForSequenceClassification.from_pretrained(\"/kaggle/working/results/checkpoint-36\")","metadata":{"execution":{"iopub.status.busy":"2023-07-02T16:55:14.677081Z","iopub.execute_input":"2023-07-02T16:55:14.678002Z","iopub.status.idle":"2023-07-02T16:55:17.873013Z","shell.execute_reply.started":"2023-07-02T16:55:14.677953Z","shell.execute_reply":"2023-07-02T16:55:17.870747Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Configuración del entrenamiento\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    metric_for_best_model=\"eval_f1\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=16,\n    learning_rate=2e-5,\n    num_train_epochs=5,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    eval_steps=500,\n    disable_tqdm=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T17:02:24.014119Z","iopub.execute_input":"2023-07-02T17:02:24.015070Z","iopub.status.idle":"2023-07-02T17:02:24.026370Z","shell.execute_reply.started":"2023-07-02T17:02:24.015032Z","shell.execute_reply":"2023-07-02T17:02:24.025403Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Entrenamiento del modelo\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T17:02:25.076321Z","iopub.execute_input":"2023-07-02T17:02:25.077044Z","iopub.status.idle":"2023-07-02T17:02:25.097801Z","shell.execute_reply.started":"2023-07-02T17:02:25.077009Z","shell.execute_reply":"2023-07-02T17:02:25.095930Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Función para la tokenización y codificación de los datos\ndef tokenize_data(data):\n    texts = data[\"text\"].tolist()\n    encoded_inputs = tokenizer(texts, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n    return encoded_inputs","metadata":{"execution":{"iopub.status.busy":"2023-07-02T17:02:37.130172Z","iopub.execute_input":"2023-07-02T17:02:37.130867Z","iopub.status.idle":"2023-07-02T17:02:37.139279Z","shell.execute_reply.started":"2023-07-02T17:02:37.130834Z","shell.execute_reply":"2023-07-02T17:02:37.137794Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_df_original = pd.read_excel('/kaggle/input/test-data-excel-formatted/test_data.xlsx')\ntrain_df_original.rename(columns={'message': 'text'}, inplace=True)\nunique_nicks = train_df_original['nick'].unique()\nfinal_df = []\nwith torch.no_grad():\n    for nick in tqdm(unique_nicks):\n        unique_rounds = train_df_original[train_df_original['nick'] == nick]['round'].unique()\n        for round_ in unique_rounds:\n            temp = train_df_original[(train_df_original['nick'] == nick) &\\\n                                     (train_df_original['round'] <= round_)][['nick' ,'text']]\n            temp = temp.groupby(['nick'])['text'].apply(lambda x: ' '.join(x)).reset_index()[['text']]\n            test_encoded = tokenize_data(temp)\n            test_dataset = Dataset.from_dict(test_encoded)\n            preds = trainer.predict(test_dataset).predictions[0]\n            pred  = list(preds).index(max(preds))\n            final_df.append([nick, round_, pred])","metadata":{"execution":{"iopub.status.busy":"2023-07-02T17:02:39.791030Z","iopub.execute_input":"2023-07-02T17:02:39.791407Z","iopub.status.idle":"2023-07-02T17:07:31.142002Z","shell.execute_reply.started":"2023-07-02T17:02:39.791375Z","shell.execute_reply":"2023-07-02T17:07:31.140961Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"100%|██████████| 149/149 [04:50<00:00,  1.95s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"final_df = pd.DataFrame(final_df)\nfinal_df.rename(columns={0: 'nick', 1: 'round', 2: 'pred'}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-07-02T17:08:15.141946Z","iopub.execute_input":"2023-07-02T17:08:15.142402Z","iopub.status.idle":"2023-07-02T17:08:15.186850Z","shell.execute_reply.started":"2023-07-02T17:08:15.142370Z","shell.execute_reply":"2023-07-02T17:08:15.185047Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Find the maximum prediction and the round where it occurs for each nick\nresult = final_df.groupby('nick').agg({'pred': 'max', 'round': 'idxmax'})\nresult.reset_index(inplace=True)\nresult","metadata":{"execution":{"iopub.status.busy":"2023-07-02T17:08:15.509256Z","iopub.execute_input":"2023-07-02T17:08:15.509759Z","iopub.status.idle":"2023-07-02T17:08:15.559790Z","shell.execute_reply.started":"2023-07-02T17:08:15.509727Z","shell.execute_reply":"2023-07-02T17:08:15.558678Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"           nick  pred  round\n0    subject184     1     21\n1    subject185     1     47\n2    subject186     1     64\n3    subject188     1     97\n4    subject190     1    141\n..          ...   ...    ...\n144   subject86     0   4980\n145    subject9     1   5026\n146   subject91     1   5067\n147   subject92     0   5113\n148   subject93     1   5163\n\n[149 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nick</th>\n      <th>pred</th>\n      <th>round</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>subject184</td>\n      <td>1</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>subject185</td>\n      <td>1</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>subject186</td>\n      <td>1</td>\n      <td>64</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>subject188</td>\n      <td>1</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>subject190</td>\n      <td>1</td>\n      <td>141</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>144</th>\n      <td>subject86</td>\n      <td>0</td>\n      <td>4980</td>\n    </tr>\n    <tr>\n      <th>145</th>\n      <td>subject9</td>\n      <td>1</td>\n      <td>5026</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>subject91</td>\n      <td>1</td>\n      <td>5067</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>subject92</td>\n      <td>0</td>\n      <td>5113</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>subject93</td>\n      <td>1</td>\n      <td>5163</td>\n    </tr>\n  </tbody>\n</table>\n<p>149 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"###########################################################################\nimport sklearn.metrics as metrics\nfrom scipy.stats import pearsonr\nimport os\nimport statistics\n# Read gold labels for binary classification (task1a, task2a, and task3a)\ndef read_qrels(qrels_file):\n    qrels={}\n    df_golden_truth = pd.read_csv(qrels_file)\n    for index, r in df_golden_truth.iterrows():\n        qrels[ r['Subject'] ] = int(r['label'])\n    print(\"\\n\"+str(len(qrels))+ \" lines read in qrels file!\\n\\n\")\n    return(qrels)\n\n# Calculation of Binary classification metrics for Binary classification tasks\nclass BinaryClassification():\n    def __init__(self, task, data, qrels):\n        self.run_results = data \n        self.qrels_b = read_qrels(qrels)\n        self.task = task\n    pass\n\n    def penalty(self,delay):\n        if self.task == \"1\": # TCA\n            p = 0.0292 # trial\n            p = 0.0411 # test\n        elif self.task == \"2\": # Depression\n            p = 0.0179 # trial\n            p = 0.0326 # test\n        else: # Unkown\n            p = 0.0308 # test\n        pen = -1.0 + 2.0/(1+np.exp(-p*(delay-1)))\n        return(pen)\n\n    def n_pos(self):\n        total_pos = 0\n        for key in self.qrels_b:\n            total_pos += self.qrels_b[key]\n        return(total_pos)\n\n    def eval_performance(self):\n        print(\"===================================================\")\n        print(\"EVALUATION:\")\n        self.run_results = self.run_results.sort_values(by=['nick'])\n        total_pos=self.n_pos()\n        erdes5 = np.zeros(len(self.run_results))\n        erdes30 = np.zeros(len(self.run_results))\n        ierdes = 0\n        true_pos = 0\n        false_pos = 0\n        latency_tps = list()\n        penalty_tps = list()\n\n        # Latency-based metrics\n        for index, r in self.run_results.iterrows():\n            try:\n                if ( self.qrels_b[ r['nick'] ] ==  r['pred'] ):\n                    if ( r['pred'] == 1 ):\n                        true_pos+=1\n                        erdes5[ierdes]=1.0 - (1.0/(1.0+np.exp( (r[\"round\"]+1) - 5.0)))\n                        erdes30[ierdes]=1.0 - (1.0/(1.0+np.exp( (r[\"round\"]+1) - 30.0)))\n                        latency_tps.append(r[\"round\"]+1)\n                        penalty_tps.append(self.penalty(r[\"round\"]+1))\n                    else:\n                        erdes5[ierdes]=0\n                        erdes30[ierdes]=0\n                else:\n                    if ( r['pred'] == 1 ):\n                        false_pos+=1\n                        erdes5[ierdes]=float(total_pos)/float(len(self.qrels_b))\n                        erdes30[ierdes]=float(total_pos)/float(len(self.qrels_b))\n                    else:\n                        erdes5[ierdes]=1\n                        erdes30[ierdes]=1\n            except KeyError:\n                print(\"User does not appear in the qrels:\"+r['nick'])\n            ierdes+=1\n\n        _speed = 1-np.median(np.array(penalty_tps))\n        if true_pos != 0 :\n            precision = float(true_pos) / float(true_pos+false_pos)    \n            recall = float(true_pos) / float(total_pos)\n            f1_erde = 2 * (precision * recall) / (precision + recall)\n            _latencyweightedF1 = f1_erde*_speed\n        else:\n            _latencyweightedF1 = 0\n            _speed = 0\n            \n        y_pred_b = self.run_results['pred'].tolist() \n        y_true = list(self.qrels_b.values()) \n\n        # Binary metrics\n        accuracy = metrics.accuracy_score(y_true, y_pred_b)\n        macro_precision = metrics.precision_score(y_true, y_pred_b, average='macro')\n        macro_recall = metrics.recall_score(y_true, y_pred_b, average='macro')\n        macro_f1 = metrics.f1_score(y_true, y_pred_b, average='macro') \n        micro_precision = metrics.precision_score(y_true, y_pred_b, average='micro')\n        micro_recall = metrics.recall_score(y_true, y_pred_b, average='micro')\n        micro_f1 = metrics.f1_score(y_true, y_pred_b, average='micro')\n\n        print(\"BINARY METRICS: =============================\")\n        print(\"Accuracy:\"+str(accuracy))\n        print(\"Macro precision:\"+str(macro_precision))\n        print(\"Macro recall:\"+str(macro_recall))\n        print(\"Macro f1:\"+str(macro_f1))\n        print(\"Micro precision:\"+str(micro_precision))\n        print(\"Micro recall:\"+str(micro_recall))\n        print(\"Micro f1:\"+str(micro_f1))\n\n        print(\"LATENCY-BASED METRICS: =============================\")\n        print(\"ERDE_5:\"+str(np.mean(erdes5))) \n        print(\"ERDE_30:\"+str(np.mean(erdes30))) \n        print(\"Median latency:\"+str(np.median(np.array(latency_tps)))) \n        print(\"Speed:\"+str(_speed)) \n        print(\"latency-weightedF1:\"+str(_latencyweightedF1)) \n        \n        return {'Acuracy': accuracy, 'Macro_P': macro_precision, 'Macro_R': macro_recall,'Macro_F1': macro_f1,'Micro_P': micro_precision, 'Micro_R': micro_recall,\n        'Micro_F1': micro_f1, 'ERDE5':np.mean(erdes5),'ERDE30': np.mean(erdes30), 'latencyTP': np.median(np.array(latency_tps)), \n        'speed': _speed, 'latency-weightedF1': _latencyweightedF1}","metadata":{"execution":{"iopub.status.busy":"2023-07-02T17:08:31.681344Z","iopub.execute_input":"2023-07-02T17:08:31.681702Z","iopub.status.idle":"2023-07-02T17:08:31.715754Z","shell.execute_reply.started":"2023-07-02T17:08:31.681673Z","shell.execute_reply":"2023-07-02T17:08:31.714263Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"metrics_ = BinaryClassification(\"2\", result, '/kaggle/input/test-gold-labels/task2_gold_a.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-02T17:08:32.385346Z","iopub.execute_input":"2023-07-02T17:08:32.385742Z","iopub.status.idle":"2023-07-02T17:08:32.415427Z","shell.execute_reply.started":"2023-07-02T17:08:32.385711Z","shell.execute_reply":"2023-07-02T17:08:32.413562Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"\n149 lines read in qrels file!\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"metrics_.eval_performance()","metadata":{"execution":{"iopub.status.busy":"2023-07-02T17:08:32.819518Z","iopub.execute_input":"2023-07-02T17:08:32.819891Z","iopub.status.idle":"2023-07-02T17:08:32.891556Z","shell.execute_reply.started":"2023-07-02T17:08:32.819859Z","shell.execute_reply":"2023-07-02T17:08:32.890346Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"===================================================\nEVALUATION:\nBINARY METRICS: =============================\nAccuracy:0.7785234899328859\nMacro precision:0.7941230997404524\nMacro recall:0.7880355846042121\nMacro f1:0.7781637717121588\nMicro precision:0.7785234899328859\nMicro recall:0.7785234899328859\nMicro f1:0.7785234899328859\nLATENCY-BASED METRICS: =============================\nERDE_5:0.536011891078397\nERDE_30:0.529302732530074\nMedian latency:1138.0\nSpeed:0.0\nlatency-weightedF1:0.0\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_149/3681996540.py:60: RuntimeWarning: overflow encountered in exp\n  erdes5[ierdes]=1.0 - (1.0/(1.0+np.exp( (r[\"round\"]+1) - 5.0)))\n/tmp/ipykernel_149/3681996540.py:61: RuntimeWarning: overflow encountered in exp\n  erdes30[ierdes]=1.0 - (1.0/(1.0+np.exp( (r[\"round\"]+1) - 30.0)))\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'Acuracy': 0.7785234899328859,\n 'Macro_P': 0.7941230997404524,\n 'Macro_R': 0.7880355846042121,\n 'Macro_F1': 0.7781637717121588,\n 'Micro_P': 0.7785234899328859,\n 'Micro_R': 0.7785234899328859,\n 'Micro_F1': 0.7785234899328859,\n 'ERDE5': 0.536011891078397,\n 'ERDE30': 0.529302732530074,\n 'latencyTP': 1138.0,\n 'speed': 0.0,\n 'latency-weightedF1': 0.0}"},"metadata":{}}]},{"cell_type":"code","source":"# -- Zip best checkpoint\n!zip /kaggle/working/results/checkpoint-36.zip /kaggle/working/results/checkpoint-36","metadata":{"execution":{"iopub.status.busy":"2023-07-02T17:15:10.411380Z","iopub.execute_input":"2023-07-02T17:15:10.411765Z","iopub.status.idle":"2023-07-02T17:15:11.595661Z","shell.execute_reply.started":"2023-07-02T17:15:10.411733Z","shell.execute_reply":"2023-07-02T17:15:11.594265Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"  adding: kaggle/working/results/checkpoint-36/ (stored 0%)\n","output_type":"stream"}]}]}